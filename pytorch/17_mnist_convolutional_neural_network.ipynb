{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c25d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dea21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f66bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a69a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.MNIST(root='D:/Dataset/MNIST_data/',\n",
    "                                                 train=True,\n",
    "                                                 transform=transforms.ToTensor(),\n",
    "                                                 download=True)\n",
    "\n",
    "mnist_test = datasets.MNIST(root='D:/Dataset/MNIST_data/',\n",
    "                                                 train=False,\n",
    "                                                 transform=transforms.ToTensor(),\n",
    "                                                 download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0569dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=mnist_train,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd0054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # first layer\n",
    "        # Image shape = (?, 28, 28, 1)\n",
    "        #   Conv   -> (?, 28, 28, 32)\n",
    "        #   Pool   -> (?, 14, 14, 32)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # second layer\n",
    "        # Image shape = (?, 14, 14, 32)\n",
    "        #   Conv   -> (?, 14, 14, 64)\n",
    "        #   Pool   -> (?, 7, 7, 64)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(7 * 7 * 64, 10, bias=True) # Full Connected Layers\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fc.weight) # Only Full Connected Layers Reset Weight\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1) # Flatten\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2323ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42896994",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ffbad39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches : 600\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "print('Total number of batches : {}'.format(total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6b20e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.218759373\n",
      "[Epoch:    2] cost = 0.0596405379\n",
      "[Epoch:    3] cost = 0.044724796\n",
      "[Epoch:    4] cost = 0.0344746411\n",
      "[Epoch:    5] cost = 0.0296490639\n",
      "[Epoch:    6] cost = 0.024573883\n",
      "[Epoch:    7] cost = 0.0204745419\n",
      "[Epoch:    8] cost = 0.017667897\n",
      "[Epoch:    9] cost = 0.0150095653\n",
      "[Epoch:   10] cost = 0.0125000346\n",
      "[Epoch:   11] cost = 0.0100905579\n",
      "[Epoch:   12] cost = 0.00961322337\n",
      "[Epoch:   13] cost = 0.00795730203\n",
      "[Epoch:   14] cost = 0.0077612591\n",
      "[Epoch:   15] cost = 0.00566769531\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "499202b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9872999787330627\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.targets.to(device)\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    corret_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = corret_prediction.float().mean()\n",
    "    print('Accuracy :', accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
